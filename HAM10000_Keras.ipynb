{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7rB_CCCtyMr",
        "outputId": "5943930a-26ca-4a48-b540-0f2454ede4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Keras-Preprocessing in /home/danny/anaconda3/lib/python3.11/site-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /home/danny/anaconda3/lib/python3.11/site-packages (from Keras-Preprocessing) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/danny/anaconda3/lib/python3.11/site-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Collecting keras-lr-finder\n",
            "  Downloading keras_lr_finder-0.1-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: keras>=2.0.0 in /home/danny/anaconda3/lib/python3.11/site-packages (from keras-lr-finder) (2.15.0)\n",
            "Requirement already satisfied: matplotlib in /home/danny/anaconda3/lib/python3.11/site-packages (from keras-lr-finder) (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (9.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/danny/anaconda3/lib/python3.11/site-packages (from matplotlib->keras-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/danny/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->keras-lr-finder) (1.16.0)\n",
            "Installing collected packages: keras-lr-finder\n",
            "Successfully installed keras-lr-finder-0.1\n",
            "Requirement already satisfied: kaggle in /home/danny/anaconda3/lib/python3.11/site-packages (1.6.4)\n",
            "Requirement already satisfied: six>=1.10 in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /home/danny/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
            "Requirement already satisfied: packaging in /home/danny/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
            "Requirement already satisfied: webencodings in /home/danny/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /home/danny/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/danny/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/danny/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install Keras-Preprocessing\n",
        "!pip install keras-lr-finder\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yNgw9sPl3YQn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir kaggle\n",
        "import os\n",
        "import json\n",
        "api_token = {\"username\":\"dereklai7\",\"key\":\"052aeb88d00b383c9144da59933f88ce\"}\n",
        "with open('kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C5Tpn2sF3cnZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chmod: cannot access '/content/kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod 600 /content/kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d0F-sn0b3fWB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp /content/kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TFB546RG9RD",
        "outputId": "5245847a-e64e-41a0-c425-f0876a235fba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading skin-cancer-mnist-ham10000.zip to .\n",
            "100%|█████████████████████████████████████▉| 5.20G/5.20G [17:15<00:00, 5.89MB/s]\n",
            "100%|██████████████████████████████████████| 5.20G/5.20G [17:15<00:00, 5.39MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download kmader/skin-cancer-mnist-ham10000  -p ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaXwEzh4G_Tu",
        "outputId": "af9028d8-e3cf-4848-bddc-d220190c3937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  skin-cancer-mnist-ham10000.zip\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "   563277  2019-10-06 16:59   HAM10000_metadata.csv\n",
            " 30807979  2019-10-06 17:03   hmnist_28_28_L.csv\n",
            " 91820383  2019-10-06 17:03   hmnist_28_28_RGB.csv\n",
            "  2537778  2019-10-06 17:03   hmnist_8_8_L.csv\n",
            "  7524968  2019-10-06 17:03   hmnist_8_8_RGB.csv\n",
            "---------                     -------\n",
            "133254385                     5 files\n"
          ]
        }
      ],
      "source": [
        "!unzip -l skin-cancer-mnist-ham10000.zip *.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZj_-cR6G_4O",
        "outputId": "408a7fbd-1fd5-4d50-a525-62dea12080c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  skin-cancer-mnist-ham10000.zip\n",
            "  inflating: HAM10000_metadata.csv   \n"
          ]
        }
      ],
      "source": [
        "!unzip  skin-cancer-mnist-ham10000.zip HAM10000_metadata.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "at-oRRWXtwyq",
        "outputId": "4cc35c61-e07a-4c1a-b18f-1e7917413d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading train.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_Input.zip ...\n",
            "downloading train_ground_truth.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_GroundTruth.zip ...\n",
            "downloading validation.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Validation_Input.zip ...\n",
            "downloading validation_ground_truth.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Validation_GroundTruth.zip ...\n",
            "downloading test.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Test_Input.zip ...\n",
            "downloading test_ground_truth.zip from https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Test_GroundTruth.zip ...\n",
            "done downloading all\n",
            "train.zip\n",
            "unzipping train.zip to folder\n",
            "train_ground_truth.zip\n",
            "unzipping train_ground_truth.zip to folder\n",
            "validation.zip\n",
            "unzipping validation.zip to folder\n",
            "validation_ground_truth.zip\n",
            "unzipping validation_ground_truth.zip to folder\n",
            "test.zip\n",
            "unzipping test.zip to folder\n",
            "test_ground_truth.zip\n",
            "unzipping test_ground_truth.zip to folder\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "\n",
        "urls = {\n",
        "    \"train\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_Input.zip\",\n",
        "    \"train_ground_truth\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_GroundTruth.zip\",\n",
        "    \"validation\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Validation_Input.zip\",\n",
        "    \"validation_ground_truth\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Validation_GroundTruth.zip\",\n",
        "    \"test\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Test_Input.zip\",\n",
        "    \"test_ground_truth\" : \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Test_GroundTruth.zip\"\n",
        "    #\"train_seg\": \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip\",\n",
        "    #\"train_seg_gt\": \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip\",\n",
        "    #\"validation_seg\": \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Validation_Input.zip\",\n",
        "    #\"validation_seg_gt\": \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Validation_GroundTruth.zip\",\n",
        "\n",
        "}\n",
        "\n",
        "def download_all():\n",
        "    for item in urls.items():\n",
        "        name = item[0]\n",
        "        url = item[1]\n",
        "        filename = f\"{name}.zip\"\n",
        "        if os.path.exists(filename):\n",
        "            print(f\"already exists file {filename}\")\n",
        "        else:\n",
        "            print(f\"downloading {filename} from {url} ...\")\n",
        "            urllib.request.urlretrieve(url, filename)\n",
        "    print(f\"done downloading all\")\n",
        "\n",
        "def unzip_all():\n",
        "    for item in urls.items():\n",
        "        name = item[0]\n",
        "        url = item[1]\n",
        "        filename = f\"{name}.zip\"\n",
        "        print(filename)\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            print(f\"unzipping {filename} to folder\")\n",
        "            zip_ref.extractall(f\"{name}\")\n",
        "\n",
        "download_all()\n",
        "unzip_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N52LXWC9T_gz"
      },
      "source": [
        "Model code starts here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yq4zT77doI0F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-05 17:37:25.097581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-05 17:37:25.097637: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-05 17:37:25.157783: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-05 17:37:25.291524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-05 17:37:26.408173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import keras as k\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import layers\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.metrics\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OIUzncg9kiY"
      },
      "source": [
        "Create Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oa1og3KA9kIs"
      },
      "outputs": [],
      "source": [
        "def get_classification_112(input_shape):\n",
        "  inputs = layers.Input(shape=input_shape)\n",
        "  densenet121 = k.applications.DenseNet121(include_top=False, input_tensor=inputs)#weights='imagenet' #Can use VGG19 instead\n",
        "  x = densenet121(inputs, training=True) #change back\n",
        "  #add optional classification layers here (if you add some youll have to change the layer indices in following functions)\n",
        "  x = layers.Conv2D(64, 3, input_shape=(112,112,3), activation='relu', padding=\"same\")(x)\n",
        "  x = layers.Conv2D(64, 3, input_shape=(112,112,3), activation='relu', padding=\"same\")(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  # output layer, change activation function based on task:\n",
        "  # multiclass classification = softmax\n",
        "  # ...\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  outputs = layers.Dense(7, activation=\"softmax\")(x)\n",
        "  classification_model_1 = k.Model(inputs=inputs, outputs=outputs, name=\"classification1\")\n",
        "  return classification_model_1\n",
        "\n",
        "\n",
        "def get_classification_224(prior): #if input shape issues, use layers.Resizing(shape=(ppfart))\n",
        "  inputs = layers.Input(shape=(224,224,3))\n",
        "\n",
        "  #new layers\n",
        "  x = layers.Conv2D(64, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu', padding='same')(inputs)\n",
        "  x = layers.Conv2D(64, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(3, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "  #print(f\"x layers: {x.layers}\")\n",
        "  pretrained = k.models.load_model(prior, custom_objects={\"f_score\": f_score}) #move metrics up??\n",
        "  pretrained.layers.pop()\n",
        "  \n",
        "  for layer in pretrained.layers[-4:]:\n",
        "    layer.trainable = False\n",
        "  x = pretrained(x)\n",
        "  outputs = layers.Dense(7, activation=\"softmax\")(x)\n",
        "  temp = k.Model(inputs=inputs, outputs=outputs, name=\"temp\")\n",
        "  temp.layers.pop()\n",
        "  inputs2 = layers.Input(shape=(224,224,3))\n",
        "  y = temp(inputs2)\n",
        "  outputs2 = layers.Dense(7, activation=\"softmax\")(y)\n",
        "  \"\"\"\n",
        "  x = pretrained.layers[1].layers[2](inputs)\n",
        "  #remove input layer, replace with new shape\n",
        "  for layer in pretrained.layers[1].layers[3:]: #every layer except for the first 3\n",
        "    x = layer(x)\n",
        "  for layer in x.layers[2]: #the rest of the layers\n",
        "    x = layer(x)\n",
        "  \"\"\"\n",
        "  #set pretrained layers to untrainable\n",
        "  #for layer in x.layers[-4:]:\n",
        "  #  layer.trainable = False\n",
        "\n",
        "  classification_model_2 = k.Model(inputs=inputs2, outputs=outputs2, name=\"classification2\")\n",
        "  return classification_model_2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHauEsx8-gCP"
      },
      "source": [
        "Define Classification Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dQDWrihW-fox"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-05 17:37:40.587382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:40.773416: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:40.773465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:40.775519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:40.775569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:40.775603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:41.009225: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:41.009303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:41.009311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2024-02-05 17:37:41.009352: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-02-05 17:37:41.009367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7551 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "input_shape=(112,112,3)\n",
        "classification_1 = get_classification_112(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOb33XptWkiK",
        "outputId": "6bf93661-09bb-451b-ff97-d81a66014ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"classification1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 112, 112, 3)]     0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 3, 3, 1024)        7037504   \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 3, 3, 64)          589888    \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 1, 1, 64)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7682759 (29.31 MB)\n",
            "Trainable params: 7599111 (28.99 MB)\n",
            "Non-trainable params: 83648 (326.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classification_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dDPeruD-l2l"
      },
      "source": [
        "Define metrics, ImageDataGenerator, and get_weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdKd4B7g-lKv",
        "outputId": "d36f47a1-fc58-4235-d36a-9443a1f7a78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 0.888866699950075, 1: 0.3305042436345482, 2: 0.9486769845232151, 3: 0.9673489765351972, 4: 0.8902646030953569, 5: 0.9885172241637543, 6: 0.9858212680978532}\n"
          ]
        }
      ],
      "source": [
        "cls_train_gt = 'train_ground_truth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'#(\"classi/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\")\n",
        "cls_val = r'validation/ISIC2018_Task3_Validation_Input/'\n",
        "cls_val_gt = \"validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
        "\n",
        "#weighted binary loss\n",
        "def get_weights(labels):\n",
        "    cols = len(labels.columns)-2 #assumes 1 column for image ids\n",
        "    weights = {}\n",
        "    for i in range(cols+1):\n",
        "        weights[i] = 1-np.mean(labels[labels.columns[i+1]].tolist())\n",
        "    return weights\n",
        "\n",
        "weights = get_weights(pd.read_csv(cls_train_gt))\n",
        "print(get_weights(pd.read_csv(cls_train_gt)))\n",
        "\n",
        "from keras import backend as K\n",
        "def f_score(y_true, y_pred, threshold=0.1, beta=2):\n",
        "    tp = tp_score(y_true, y_pred, threshold)\n",
        "    fp = fp_score(y_true, y_pred, threshold)\n",
        "    fn = fn_score(y_true, y_pred, threshold)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    return (1+beta**2) * ((precision * recall) / ((beta**2)*precision + recall))\n",
        "\n",
        "def tp_score(y_true, y_pred, threshold=0.1):\n",
        "    tp_3d = K.concatenate(\n",
        "        [\n",
        "            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n",
        "            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n",
        "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
        "        ], axis=1\n",
        "    )\n",
        "    tp = K.sum(K.cast(K.all(tp_3d, axis=1), 'int32'))\n",
        "    return tp\n",
        "\n",
        "def fp_score(y_true, y_pred, threshold=0.1):\n",
        "    fp_3d = K.concatenate(\n",
        "        [\n",
        "            K.cast(K.expand_dims(K.flatten(K.abs(y_true - K.ones_like(y_true)))), 'bool'),\n",
        "            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n",
        "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
        "        ], axis=-1\n",
        "    )\n",
        "\n",
        "    fp = K.sum(K.cast(K.all(fp_3d, axis=1), 'int32'))\n",
        "    return fp\n",
        "\n",
        "def fn_score(y_true, y_pred, threshold=0.1):\n",
        "    fn_3d = K.concatenate(\n",
        "        [\n",
        "            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n",
        "            K.cast(K.expand_dims(K.flatten(K.abs(K.cast(K.greater(y_pred, K.constant(threshold)), 'float') - K.ones_like(y_pred)))), 'bool'),\n",
        "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
        "        ], axis=1\n",
        "    )\n",
        "\n",
        "    fn = K.sum(K.cast(K.all(fn_3d, axis=1), 'int32'))\n",
        "    return fn\n",
        "\n",
        "def precision_score(y_true, y_pred, threshold=0.1):\n",
        "    tp = tp_score(y_true, y_pred, threshold)\n",
        "    fp = fp_score(y_true, y_pred, threshold)\n",
        "    return tp / (tp + fp)\n",
        "\n",
        "def recall_score(y_true, y_pred, threshold=0.1):\n",
        "    tp = tp_score(y_true, y_pred, threshold)\n",
        "    fn = fn_score(y_true, y_pred, threshold)\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "cls_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True) #Can also add rotation, width/height shifting...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0aqQGvVFcMr"
      },
      "source": [
        "Evaluation \"Metrics\" Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eD3YY-FJFeiL"
      },
      "outputs": [],
      "source": [
        "def print_metrics(history, epochs):\n",
        "  train_loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  train_acc  = history.history['accuracy']\n",
        "  val_acc    = history.history['val_accuracy']\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.plot(range(epochs), train_loss)\n",
        "  plt.plot(range(epochs), val_loss)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.plot(range(epochs), train_acc)\n",
        "  plt.plot(range(epochs), val_acc)\n",
        "\n",
        "def accuracy_from_val(model, val_x_path, val_y_path):\n",
        "  preds = model.predict(val_x_path)\n",
        "  acc = sklearn.metrics.accuracy_score(preds, val_y_path)\n",
        "  print('The accuracy is {0} % .'.format(acc*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbHh2oyF-xuR"
      },
      "source": [
        "Load & preprocess data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M0CM_qjlBoCF",
        "outputId": "5c2fdb44-97a4-40a0-b211-19f22fda7537"
      },
      "outputs": [],
      "source": [
        "#Prepare val_y csv & train_y_h10000\n",
        "val_y = \"validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
        "train_y_h10000 = 'HAM10000_metadata.csv'\n",
        "\n",
        "df_val_meta = pd.read_csv(val_y)\n",
        "df_train = pd.read_csv(train_y_h10000)\n",
        "\n",
        "#add suffixes\n",
        "df_val_meta['img_id'] = df_val_meta['image'] + '.jpg'\n",
        "df_train['img_id'] = df_train['image_id'] + '.jpg'\n",
        "\n",
        "#Replace all binarized labels with their corresponding string label\n",
        "df_val_meta['bits_num'] = df_val_meta['MEL'] * 1 + df_val_meta['NV'] * 2 + df_val_meta['BCC'] *4 + df_val_meta['AKIEC']*8 +  \\\n",
        "    df_val_meta['BKL']*16 + df_val_meta['DF']*32 + + df_val_meta['VASC']*64\n",
        "\n",
        "labels = { 1.0 :\"mel\", 2.0:\"nv\", 4.0:\"bcc\", 8.0:\"akiec\", 16.0:\"bkl\", 32.0:\"df\", 64.0:\"vasc\" }\n",
        "\n",
        "def to_dx(bits_num):\n",
        "    return labels.get(bits_num)\n",
        "\n",
        "df_val_meta[\"dx\"] = df_val_meta[\"bits_num\"].apply(to_dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndf_val_meta[\"dx2\"] = k.utils.to_categorical(df_val_meta[\"dx\"], 7)\\ndf_train[\"dx2\"] = k.utils.to_categorical(df_train[\"dx\"], 7)\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_val_meta[\"dx_encoded\"] = label_encoder.fit_transform(df_val_meta[\"dx\"])\n",
        "df_train[\"dx_encoded\"] = label_encoder.fit_transform(df_train[\"dx\"])\n",
        "\n",
        "\"\"\"\n",
        "df_val_meta[\"dx2\"] = k.utils.to_categorical(df_val_meta[\"dx\"], 7)\n",
        "df_train[\"dx2\"] = k.utils.to_categorical(df_train[\"dx\"], 7)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0]]\n",
            "(193,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "lb.fit([[0,0,0,0,0,0,1], [1,0,0,0,0,0,0]])\n",
        "print(lb.transform([0,1,2,3,4]))\n",
        "\n",
        "print(df_val_meta[\"dx_encoded\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VwiT-mfbNnY7",
        "outputId": "f99dbda2-cbc6-4354-d45f-6eaba200ca89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "      <th>img_id</th>\n",
              "      <th>bits_num</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>ISIC_0034371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISIC_0034371.jpg</td>\n",
              "      <td>16.0</td>\n",
              "      <td>bkl</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>ISIC_0034474</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISIC_0034474.jpg</td>\n",
              "      <td>2.0</td>\n",
              "      <td>nv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>ISIC_0034407</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISIC_0034407.jpg</td>\n",
              "      <td>2.0</td>\n",
              "      <td>nv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>ISIC_0034417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISIC_0034417.jpg</td>\n",
              "      <td>2.0</td>\n",
              "      <td>nv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>ISIC_0034518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>ISIC_0034518.jpg</td>\n",
              "      <td>2.0</td>\n",
              "      <td>nv</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            image  MEL   NV  BCC  AKIEC  BKL   DF  VASC            img_id  \\\n",
              "47   ISIC_0034371  0.0  0.0  0.0    0.0  1.0  0.0   0.0  ISIC_0034371.jpg   \n",
              "144  ISIC_0034474  0.0  1.0  0.0    0.0  0.0  0.0   0.0  ISIC_0034474.jpg   \n",
              "80   ISIC_0034407  0.0  1.0  0.0    0.0  0.0  0.0   0.0  ISIC_0034407.jpg   \n",
              "90   ISIC_0034417  0.0  1.0  0.0    0.0  0.0  0.0   0.0  ISIC_0034417.jpg   \n",
              "187  ISIC_0034518  0.0  1.0  0.0    0.0  0.0  0.0   0.0  ISIC_0034518.jpg   \n",
              "\n",
              "     bits_num   dx  dx_encoded  \n",
              "47       16.0  bkl           2  \n",
              "144       2.0   nv           5  \n",
              "80        2.0   nv           5  \n",
              "90        2.0   nv           5  \n",
              "187       2.0   nv           5  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val_meta.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>img_id</th>\n",
              "      <th>dx_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2332</th>\n",
              "      <td>HAM_0004765</td>\n",
              "      <td>ISIC_0031217</td>\n",
              "      <td>vasc</td>\n",
              "      <td>histo</td>\n",
              "      <td>15.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "      <td>ISIC_0031217.jpg</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4829</th>\n",
              "      <td>HAM_0005516</td>\n",
              "      <td>ISIC_0028748</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>ISIC_0028748.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2831</th>\n",
              "      <td>HAM_0002689</td>\n",
              "      <td>ISIC_0026687</td>\n",
              "      <td>bcc</td>\n",
              "      <td>histo</td>\n",
              "      <td>60.0</td>\n",
              "      <td>male</td>\n",
              "      <td>lower extremity</td>\n",
              "      <td>ISIC_0026687.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5431</th>\n",
              "      <td>HAM_0004688</td>\n",
              "      <td>ISIC_0032000</td>\n",
              "      <td>nv</td>\n",
              "      <td>follow_up</td>\n",
              "      <td>60.0</td>\n",
              "      <td>male</td>\n",
              "      <td>upper extremity</td>\n",
              "      <td>ISIC_0032000.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>HAM_0001928</td>\n",
              "      <td>ISIC_0032537</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>55.0</td>\n",
              "      <td>male</td>\n",
              "      <td>chest</td>\n",
              "      <td>ISIC_0032537.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        lesion_id      image_id    dx    dx_type   age   sex     localization  \\\n",
              "2332  HAM_0004765  ISIC_0031217  vasc      histo  15.0  male             face   \n",
              "4829  HAM_0005516  ISIC_0028748    nv  follow_up  50.0  male          abdomen   \n",
              "2831  HAM_0002689  ISIC_0026687   bcc      histo  60.0  male  lower extremity   \n",
              "5431  HAM_0004688  ISIC_0032000    nv  follow_up  60.0  male  upper extremity   \n",
              "1582  HAM_0001928  ISIC_0032537   mel      histo  55.0  male            chest   \n",
              "\n",
              "                img_id  dx_encoded  \n",
              "2332  ISIC_0031217.jpg           6  \n",
              "4829  ISIC_0028748.jpg           5  \n",
              "2831  ISIC_0026687.jpg           1  \n",
              "5431  ISIC_0032000.jpg           5  \n",
              "1582  ISIC_0032537.jpg           4  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lesion_id       0\n",
            "image_id        0\n",
            "dx              0\n",
            "dx_type         0\n",
            "age             0\n",
            "sex             0\n",
            "localization    0\n",
            "img_id          0\n",
            "dx_encoded      0\n",
            "dtype: int64\n",
            "image         0\n",
            "MEL           0\n",
            "NV            0\n",
            "BCC           0\n",
            "AKIEC         0\n",
            "BKL           0\n",
            "DF            0\n",
            "VASC          0\n",
            "img_id        0\n",
            "bits_num      0\n",
            "dx            0\n",
            "dx_encoded    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_train.isnull().sum())\n",
        "print(df_val_meta.isnull().sum())\n",
        "\n",
        "df_train[\"age\"].fillna(50, inplace=True)\n",
        "\n",
        "print(df_train.isnull().sum())\n",
        "print(df_val_meta.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmD3FFJE-xJR",
        "outputId": "3bbe9b31-1a28-4890-eb27-be74cd379a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10015 validated image filenames belonging to 7 classes.\n",
            "Found 193 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "val_x = 'validation/ISIC2018_Task3_Validation_Input/'\n",
        "val_y = \"validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
        "\n",
        "train_x = 'train/ISIC2018_Task3_Training_Input/'\n",
        "train_y = 'train_ground_truth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "seed=123\n",
        "\n",
        "train_data = cls_datagen.flow_from_dataframe(df_train, directory=train_x, x_col=\"img_id\", y_col=\"dx\", target_size=(112,112), color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True)\n",
        "val_data = cls_datagen.flow_from_dataframe(df_val_meta, directory=val_x, x_col=\"img_id\", y_col=\"dx\", target_size=(112,112), color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwBAnvYReraJ",
        "outputId": "886216cc-2981-4d14-a76c-47b3b711657b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49\n",
            "2504\n",
            "10015\n"
          ]
        }
      ],
      "source": [
        "print(len(val_data))\n",
        "print(len(train_data))\n",
        "print(train_data.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FAr1fznEYmV"
      },
      "source": [
        "Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "GCUOlkCwEYDv",
        "outputId": "064a23d8-e79f-4115-a3c1-04b3c2c240c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\u001b[38;5;66;03m#k.callbacks.EarlyStopping(patience=5)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m epochs1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m----> 6\u001b[0m history1 \u001b[38;5;241m=\u001b[39m classification_1\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39mepochs1, steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch, class_weight\u001b[38;5;241m=\u001b[39mweights, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_data), validation_data\u001b[38;5;241m=\u001b[39mval_data, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[1;32m      8\u001b[0m classification_1\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification_1.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m print_metrics(history1, epochs1)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwds, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m    696\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    697\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m api\u001b[38;5;241m.\u001b[39mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[38;5;241m=\u001b[39mconverter\u001b[38;5;241m.\u001b[39mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[38;5;241m=\u001b[39mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filef8fcmg14.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(run_step, args\u001b[38;5;241m=\u001b[39m(data,))\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended\u001b[38;5;241m.\u001b[39mcall_for_each_replica(fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(data)\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:276\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(var_list):\n\u001b[1;32m    274\u001b[0m             var_list \u001b[38;5;241m=\u001b[39m var_list()\n\u001b[0;32m--> 276\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, var_list)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m imperative_grad\u001b[38;5;241m.\u001b[39mimperative_grad(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape,\n\u001b[1;32m   1068\u001b[0m     flat_targets,\n\u001b[1;32m   1069\u001b[0m     flat_sources,\n\u001b[1;32m   1070\u001b[0m     output_gradients\u001b[38;5;241m=\u001b[39moutput_gradients,\n\u001b[1;32m   1071\u001b[0m     sources_raw\u001b[38;5;241m=\u001b[39mflat_sources_raw,\n\u001b[1;32m   1072\u001b[0m     unconnected_gradients\u001b[38;5;241m=\u001b[39munconnected_gradients)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_tape,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str(unconnected_gradients\u001b[38;5;241m.\u001b[39mvalue))\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/nn_grad.py:594\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    575\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    584\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_input(\n\u001b[1;32m    585\u001b[0m         shape_0,\n\u001b[1;32m    586\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    587\u001b[0m         grad,\n\u001b[1;32m    588\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m    589\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m    590\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    591\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    592\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    593\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format),\n\u001b[0;32m--> 594\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_filter(\n\u001b[1;32m    595\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    596\u001b[0m         shape_1,\n\u001b[1;32m    597\u001b[0m         grad,\n\u001b[1;32m    598\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m    599\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m    600\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    601\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    602\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    603\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format)\n\u001b[1;32m    604\u001b[0m ]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_nn_ops.py:1536\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1533\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected list for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2d_backprop_filter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dilations)\n\u001b[1;32m   1535\u001b[0m dilations \u001b[38;5;241m=\u001b[39m [_execute\u001b[38;5;241m.\u001b[39mmake_int(_i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m dilations]\n\u001b[0;32m-> 1536\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m _op_def_library\u001b[38;5;241m.\u001b[39m_apply_op_helper(\n\u001b[1;32m   1537\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv2DBackpropFilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, filter_sizes\u001b[38;5;241m=\u001b[39mfilter_sizes,\n\u001b[1;32m   1538\u001b[0m                               out_backprop\u001b[38;5;241m=\u001b[39mout_backprop, strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m   1539\u001b[0m                               padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   1540\u001b[0m                               use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m   1541\u001b[0m                               explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m   1542\u001b[0m                               data_format\u001b[38;5;241m=\u001b[39mdata_format, dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m   1543\u001b[0m                               name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1544\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:776\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    771\u001b[0m   _ExtractDefaultTypesAndAllowedTypes(op_def, default_type_attr_map,\n\u001b[1;32m    772\u001b[0m                                       allowed_list_attr_map)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# Requires that op_def has passed validation (using the C++\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# ValidateOpDef() from ../framework/op_def_util.h).\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[1;32m    778\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    779\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    780\u001b[0m                            input_types)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:472\u001b[0m, in \u001b[0;36mFuncGraph.as_default.<locals>.inner_cm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# We ignore device placements from any outer scopes while tracing the\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# function when possible, to avoid hard-coding them in the function\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# graph. \"Default\" placements come from the PartitionedCallOp's placement,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# 1. device stack is callable\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# 2. When using distribution strategy with legacy graph mode.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m old_device_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_function_stack\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     (device_stack_has_callable(graph\u001b[38;5;241m.\u001b[39m_device_function_stack) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    471\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy_stack \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions()))):\n\u001b[1;32m    473\u001b[0m   \u001b[38;5;66;03m# Hard-code devices from device functions in the function body\u001b[39;00m\n\u001b[1;32m    474\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_function_stack \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_device_function_stack\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    476\u001b[0m old_creator_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creator_stack\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:4760\u001b[0m, in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4759\u001b[0m   outer_context, _ \u001b[38;5;241m=\u001b[39m _get_outer_context_and_inner_device_stack()\n\u001b[0;32m-> 4760\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m outer_context():\n\u001b[1;32m   4761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1011\u001b[0m, in \u001b[0;36mContext._mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1006\u001b[0m ctx\u001b[38;5;241m.\u001b[39mis_eager \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m==\u001b[39m EAGER_MODE\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m EAGER_MODE:\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;66;03m# Entering graph mode does not provide us with sufficient information to\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m   \u001b[38;5;66;03m# record a context switch; graph-based context switches are only logged\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m   \u001b[38;5;66;03m# when a graph is registered as the default graph.\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_switches\u001b[38;5;241m.\u001b[39mpush(\u001b[38;5;28;01mFalse\u001b[39;00m, eager_mode, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m   \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:2143\u001b[0m, in \u001b[0;36mContext.context_switches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set the number of retries to use when calling SetServerDef.\u001b[39;00m\n\u001b[1;32m   2131\u001b[0m \n\u001b[1;32m   2132\u001b[0m \u001b[38;5;124;03m  In cases where many servers run in high-preemption environments, jobs could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;124;03m      max value 10s, and exponent 1.3.\u001b[39;00m\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m   2141\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_server_def_retries \u001b[38;5;241m=\u001b[39m retries\n\u001b[0;32m-> 2143\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontext_switches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a stack of context switches.\"\"\"\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_switches\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.002) #Modify learning rate if needed\n",
        "classification_1.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f_score, 'AUC'])\n",
        "callbacks = []#k.callbacks.EarlyStopping(patience=5)\n",
        "epochs1 = 25\n",
        "batch_size = 4\n",
        "steps_per_epoch = 4\n",
        "\n",
        "history1 = classification_1.fit(train_data, epochs=epochs1, steps_per_epoch=steps_per_epoch, class_weight=weights, batch_size=len(train_data), validation_data=val_data, verbose=1, callbacks=callbacks)\n",
        "\n",
        "classification_1.save(\"classification_1.keras\")\n",
        "\n",
        "print_metrics(history1, epochs1)\n",
        "\n",
        "\n",
        "# accuracy_from_val(classification_1, val_x, val_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "f1Q3No7jQiEE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"classification2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " temp (Functional)           (None, 7)                 7723266   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7723322 (29.46 MB)\n",
            "Trainable params: 7621235 (29.07 MB)\n",
            "Non-trainable params: 102087 (398.78 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Classification Stage 2\n",
        "classification_2 = get_classification_224(\"classification_1.keras\")\n",
        "classification_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10015 validated image filenames belonging to 7 classes.\n",
            "Found 193 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size2 = 4\n",
        "train_data2 = cls_datagen.flow_from_dataframe(df_train, directory=train_x, x_col=\"img_id\", y_col=\"dx\", target_size=(224,224), color_mode='rgb', class_mode='categorical', batch_size=batch_size2, shuffle=True)\n",
        "val_data2 = cls_datagen.flow_from_dataframe(df_val_meta, directory=val_x, x_col=\"img_id\", y_col=\"dx\", target_size=(224,224), color_mode='rgb', class_mode='categorical', batch_size=batch_size2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-05 20:43:53.238468: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2024-02-05 20:43:53.362891: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2024-02-05 20:43:53.546510: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2024-02-05 20:43:59.372850: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3bb40cc940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-02-05 20:43:59.372890: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1707194639.424562     978 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 47s 2s/step - loss: 1.8096 - accuracy: 0.0625 - f_score: 0.4545 - auc: 0.6631 - val_loss: 1.8658 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7159\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - 2s 644ms/step - loss: 1.7433 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.6992 - val_loss: 1.8637 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7147\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - 2s 684ms/step - loss: 1.5316 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.6081 - val_loss: 1.8626 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7148\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - 2s 681ms/step - loss: 1.7951 - accuracy: 0.1250 - f_score: 0.4545 - auc: 0.6738 - val_loss: 1.8618 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7140\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - 2s 665ms/step - loss: 1.7941 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.7760 - val_loss: 1.8600 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7142\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - 13s 4s/step - loss: 1.6204 - accuracy: 0.0667 - f_score: 0.4545 - auc: 0.7319 - val_loss: 1.8590 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7161\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - 2s 649ms/step - loss: 1.8055 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.7913 - val_loss: 1.8570 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7184\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - 2s 676ms/step - loss: 1.5388 - accuracy: 0.1250 - f_score: 0.4545 - auc: 0.7731 - val_loss: 1.8557 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7345\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - 2s 686ms/step - loss: 1.4423 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.6702 - val_loss: 1.8550 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7415\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - 2s 678ms/step - loss: 1.7835 - accuracy: 0.0625 - f_score: 0.4545 - auc: 0.7526 - val_loss: 1.8535 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7599\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - 2s 689ms/step - loss: 1.7203 - accuracy: 0.0000e+00 - f_score: 0.4545 - auc: 0.7777 - val_loss: 1.8521 - val_accuracy: 0.0415 - val_f_score: 0.4545 - val_auc: 0.7646\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - 2s 663ms/step - loss: 1.7876 - accuracy: 0.3125 - f_score: 0.4545 - auc: 0.7324 - val_loss: 1.8505 - val_accuracy: 0.3264 - val_f_score: 0.4545 - val_auc: 0.7756\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - 2s 663ms/step - loss: 1.7982 - accuracy: 0.4375 - f_score: 0.4545 - auc: 0.7116 - val_loss: 1.8493 - val_accuracy: 0.6114 - val_f_score: 0.4545 - val_auc: 0.7735\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - 2s 674ms/step - loss: 1.7955 - accuracy: 0.6875 - f_score: 0.4545 - auc: 0.7741 - val_loss: 1.8475 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7775\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - 2s 628ms/step - loss: 1.7042 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.7816 - val_loss: 1.8465 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7788\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - 2s 674ms/step - loss: 1.7027 - accuracy: 0.7500 - f_score: 0.4545 - auc: 0.8314 - val_loss: 1.8449 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7770\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - 2s 700ms/step - loss: 1.7599 - accuracy: 0.7500 - f_score: 0.4545 - auc: 0.8346 - val_loss: 1.8428 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7811\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - 2s 705ms/step - loss: 1.7176 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.7383 - val_loss: 1.8421 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7835\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - 2s 659ms/step - loss: 1.5355 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.8285 - val_loss: 1.8405 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7860\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - 2s 669ms/step - loss: 1.6849 - accuracy: 0.6875 - f_score: 0.4545 - auc: 0.8301 - val_loss: 1.8395 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.7909\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - 2s 693ms/step - loss: 1.7046 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.7676 - val_loss: 1.8381 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8029\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - 2s 675ms/step - loss: 1.7027 - accuracy: 0.6875 - f_score: 0.4545 - auc: 0.7988 - val_loss: 1.8365 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8128\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - 2s 691ms/step - loss: 1.7317 - accuracy: 0.5625 - f_score: 0.4545 - auc: 0.6862 - val_loss: 1.8357 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8157\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - 2s 656ms/step - loss: 1.5591 - accuracy: 0.5000 - f_score: 0.4545 - auc: 0.7288 - val_loss: 1.8346 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8193\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - 2s 688ms/step - loss: 1.7703 - accuracy: 0.7333 - f_score: 0.4545 - auc: 0.8385 - val_loss: 1.8330 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8233\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - 2s 665ms/step - loss: 1.6226 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.8516 - val_loss: 1.8317 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8222\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - 2s 704ms/step - loss: 1.5339 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.8730 - val_loss: 1.8307 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8185\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - 2s 656ms/step - loss: 1.7802 - accuracy: 0.7500 - f_score: 0.4545 - auc: 0.8359 - val_loss: 1.8294 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8170\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - 2s 693ms/step - loss: 1.7319 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.7461 - val_loss: 1.8280 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8156\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - 2s 746ms/step - loss: 1.6952 - accuracy: 0.5625 - f_score: 0.4545 - auc: 0.7721 - val_loss: 1.8268 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8156\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - 2s 707ms/step - loss: 1.6641 - accuracy: 0.8750 - f_score: 0.4545 - auc: 0.9557 - val_loss: 1.8252 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8143\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - 2s 686ms/step - loss: 1.6839 - accuracy: 0.5625 - f_score: 0.4545 - auc: 0.7894 - val_loss: 1.8242 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8143\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - 2s 665ms/step - loss: 1.6008 - accuracy: 0.8125 - f_score: 0.4545 - auc: 0.8838 - val_loss: 1.8220 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8165\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - 2s 689ms/step - loss: 1.6423 - accuracy: 0.5000 - f_score: 0.4545 - auc: 0.6755 - val_loss: 1.8211 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8215\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - 2s 673ms/step - loss: 1.6683 - accuracy: 0.5625 - f_score: 0.4545 - auc: 0.8171 - val_loss: 1.8202 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8225\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - 2s 670ms/step - loss: 1.7508 - accuracy: 0.7500 - f_score: 0.4545 - auc: 0.8555 - val_loss: 1.8187 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8227\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - 2s 685ms/step - loss: 1.6138 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.7949 - val_loss: 1.8173 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8256\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - 2s 683ms/step - loss: 1.6527 - accuracy: 0.8125 - f_score: 0.4545 - auc: 0.9059 - val_loss: 1.8163 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8212\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - 2s 677ms/step - loss: 1.6757 - accuracy: 0.6875 - f_score: 0.4545 - auc: 0.8096 - val_loss: 1.8143 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8180\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - 2s 684ms/step - loss: 1.7306 - accuracy: 0.6250 - f_score: 0.4545 - auc: 0.8392 - val_loss: 1.8135 - val_accuracy: 0.6373 - val_f_score: 0.4545 - val_auc: 0.8152\n"
          ]
        }
      ],
      "source": [
        "l_rate_2 = 0.001\n",
        "epochs2 = 40\n",
        "steps_per_epoch2 = 4\n",
        "\n",
        "optimizer2 = tf.keras.optimizers.SGD(learning_rate=l_rate_2)\n",
        "classification_2.compile(optimizer=optimizer2, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f_score, 'AUC'])\n",
        "callbacks = []#k.callbacks.EarlyStopping(patience=5)\n",
        "\n",
        "history2 = classification_2.fit(train_data2, epochs=epochs2, steps_per_epoch=steps_per_epoch2, class_weight=weights, batch_size=len(train_data), validation_data=val_data2, verbose=1, callbacks=callbacks)\n",
        "classification_2.save(\"classification_2.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Mn8HBwGqIT"
      },
      "source": [
        "Evaluation and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mtlDhWUdGr7N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "True Label:            image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
            "11  ISIC_0034535  0.0  0.0  0.0    0.0  1.0  0.0   0.0\n",
            "Predicted Scores: [[0.02994625 0.0137396  0.10090231 0.01118257 0.05243101 0.7813926\n",
            "  0.01040569]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This image most likely belongs to DF with a 78.14 percent confidence.\n"
          ]
        }
      ],
      "source": [
        "class_names=[\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "\n",
        "pred_folder = \"test/ISIC2018_Task3_Test_Input\"\n",
        "pred_image = \"ISIC_00345\" + str(np.random.randint(10, 99))\n",
        "labels_path = \"test_ground_truth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\"\n",
        "\n",
        "pred_label_df = pd.read_csv(labels_path)\n",
        "pred_label_true = pred_label_df.loc[pred_label_df['image']==pred_image]\n",
        "\n",
        "test_image = np.array(cv2.imread(os.path.join(pred_folder, pred_image) + \".jpg\"))\n",
        "pred_image = cv2.resize(test_image, (112,112))\n",
        "\n",
        "img_array = tf.keras.utils.img_to_array(pred_image)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "score = classification_1.predict(img_array)\n",
        "label_name = class_names[np.argmax(score)]\n",
        "confidence_percent = 100 * np.max(score)\n",
        "\n",
        "print(f\"True Label: {pred_label_true}\")\n",
        "\n",
        "print(f\"Predicted Scores: {score}\")\n",
        "plt.imshow(score, interpolation=\"nearest\")\n",
        "plt.show()\n",
        "\n",
        "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(label_name, confidence_percent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmZGABb_G1YK"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix\n",
        "x_test_path = \"test/ISIC2018_Task3_Test_Input\"\n",
        "y_test_path = \"test_ground_truth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\"\n",
        "\n",
        "x_test, y_test = load_images_and_labels(x_test_path, y_test_path, len(pd.read_csv(y_test_path)), (112,112), True)\n",
        "\n",
        "y_prediction = classification.predict(x_test)\n",
        "y_prediction = np.argmax (y_prediction, axis = 1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(result, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(result.shape[0]):\n",
        "    for j in range(result.shape[1]):\n",
        "        ax.text(x=j, y=i,s=np.round(result[i, j], 3), va='center', ha='center', size='xx-large')\n",
        "\n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkWLUSNgG7z9"
      },
      "source": [
        "Converting to .tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojy_mbvjG4v-"
      },
      "outputs": [],
      "source": [
        "def convert_to_tflite(model, name):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(str(name), 'wb') as f:\n",
        "      f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
