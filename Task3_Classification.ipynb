{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:52:32.851393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-03 15:52:32.851433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-03 15:52:32.853434: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-03 15:52:32.871842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-03 15:52:33.863159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from keras import layers\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import clone_model\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "#import shutil\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:52:39.182489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.227844: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.227903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.228957: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.229003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.229039: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.355156: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.355241: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.355248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-03 15:52:39.355319: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-03 15:52:39.355337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7551 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " densenet121 (Functional)    (None, 8, 8, 1024)        7037504   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 64)          589888    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8, 8, 64)          256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 96)          55392     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 8, 96)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 96)          384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 96)          83040     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 8, 96)          0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 96)          384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 4, 4, 96)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         110720    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8029767 (30.63 MB)\n",
      "Trainable params: 7945095 (30.31 MB)\n",
      "Non-trainable params: 84672 (330.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#classification\n",
    "\n",
    "def classi(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    #vgg19 = k.applications.VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    #x = vgg19(inputs, training=False)\n",
    "    densenet121 = k.applications.DenseNet121(include_top=False, input_tensor=inputs)\n",
    "    x = densenet121(inputs, training=True)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #classi layers\n",
    "    for filters in [96, 128]:#, 256]:#, 320]:#, 512]:#, 1024, 2048]:\n",
    "        x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPool2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    #output\n",
    "    x = layers.Dropout(rate=0.2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    #x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    output = layers.Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "    model = k.Model(inputs=inputs, outputs=output, name=\"classification\")\n",
    "    return model\n",
    "\n",
    "classification = classi((256,256,3))\n",
    "classification.summary()\n",
    "\n",
    "#classification.save(\"classification.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.888866699950075, 1: 0.3305042436345482, 2: 0.9486769845232151, 3: 0.9673489765351972, 4: 0.8902646030953569, 5: 0.9885172241637543, 6: 0.9858212680978532}\n"
     ]
    }
   ],
   "source": [
    "cls_train_gt = 'train_ground_truth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'#(\"classi/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\")\n",
    "cls_val = r'validation/ISIC2018_Task3_Validation_Input/'\n",
    "cls_val_gt = \"validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
    "\n",
    "#weighted binary loss\n",
    "def get_weights(labels):\n",
    "    cols = len(labels.columns)-2 #assumes 1 column for image ids\n",
    "    weights = {}\n",
    "    for i in range(cols+1):\n",
    "        weights[i] = 1-np.mean(labels[labels.columns[i+1]].tolist())\n",
    "    return weights\n",
    "\n",
    "print(get_weights(pd.read_csv(cls_train_gt)))\n",
    "\n",
    "from keras import backend as K\n",
    "def f_score(y_true, y_pred, threshold=0.1, beta=2):\n",
    "    tp = tp_score(y_true, y_pred, threshold)\n",
    "    fp = fp_score(y_true, y_pred, threshold)\n",
    "    fn = fn_score(y_true, y_pred, threshold)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return (1+beta**2) * ((precision * recall) / ((beta**2)*precision + recall))\n",
    "\n",
    "def tp_score(y_true, y_pred, threshold=0.1):\n",
    "    tp_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n",
    "            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n",
    "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
    "        ], axis=1\n",
    "    )\n",
    "    tp = K.sum(K.cast(K.all(tp_3d, axis=1), 'int32'))\n",
    "    return tp\n",
    "\n",
    "def fp_score(y_true, y_pred, threshold=0.1):\n",
    "    fp_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(K.expand_dims(K.flatten(K.abs(y_true - K.ones_like(y_true)))), 'bool'),\n",
    "            K.cast(K.expand_dims(K.flatten(K.greater(y_pred, K.constant(threshold)))), 'bool'),\n",
    "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
    "        ], axis=-1\n",
    "    )\n",
    "\n",
    "    fp = K.sum(K.cast(K.all(fp_3d, axis=1), 'int32'))\n",
    "    return fp\n",
    "\n",
    "def fn_score(y_true, y_pred, threshold=0.1):\n",
    "    fn_3d = K.concatenate(\n",
    "        [\n",
    "            K.cast(K.expand_dims(K.flatten(y_true)), 'bool'),\n",
    "            K.cast(K.expand_dims(K.flatten(K.abs(K.cast(K.greater(y_pred, K.constant(threshold)), 'float') - K.ones_like(y_pred)))), 'bool'),\n",
    "            K.cast(K.ones_like(K.expand_dims(K.flatten(y_pred))), 'bool')\n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "    fn = K.sum(K.cast(K.all(fn_3d, axis=1), 'int32'))\n",
    "    return fn\n",
    "\n",
    "def precision_score(y_true, y_pred, threshold=0.1):\n",
    "    tp = tp_score(y_true, y_pred, threshold)\n",
    "    fp = fp_score(y_true, y_pred, threshold)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall_score(y_true, y_pred, threshold=0.1):\n",
    "    tp = tp_score(y_true, y_pred, threshold)\n",
    "    fn = fn_score(y_true, y_pred, threshold)\n",
    "    return tp / (tp + fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_datagen = ImageDataGenerator(rotation_range=0,\n",
    "                                horizontal_flip=True,\n",
    "                                vertical_flip=True,\n",
    "                                width_shift_range=0.15,\n",
    "                                height_shift_range=0.15\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading classification labels and images.\n",
    "# Standard Function, random sampling\n",
    "def load_images_and_labels(images_path, labels_path, batch_size, image_shape, verbose=False):\n",
    "    ds_images = []\n",
    "    ds_labels = []\n",
    "    data_indexes = []\n",
    "    labels = pd.read_csv(labels_path)\n",
    "    images = os.listdir(images_path)\n",
    "    if verbose:\n",
    "        print(f\"loading images from {images_path} and labels from {labels_path}\")\n",
    "    for i in range(batch_size):\n",
    "        random_index = np.random.randint(0, len(images)-2)\n",
    "        if random_index >= len(images):\n",
    "            random_index -=1\n",
    "        img = cv2.imread(os.path.join(images_path, images[random_index]))\n",
    "        row = labels.iloc[random_index, 1:]\n",
    "\n",
    "        if img is not None and row is not None:\n",
    "            if random_index not in data_indexes:\n",
    "                data_indexes.append(random_index)\n",
    "                ds_images.append(np.array(cv2.resize(img, dsize=image_shape)))\n",
    "                ds_labels.append(row.values)\n",
    "    return np.array(ds_images).astype(np.int16), np.array(ds_labels).astype(np.int16)\n",
    "\n",
    "# Equal Sampling\n",
    "def load_images_and_labels_equal(images_path, labels_path, batch_size, num_classes, image_shape, verbose=False):\n",
    "    ds_images = []\n",
    "    ds_labels = []\n",
    "    samples_per_class = []\n",
    "    class_indexes = []\n",
    "    labels = pd.read_csv(labels_path)\n",
    "    class_names = np.array(labels.columns[1:])\n",
    "    images = os.listdir(images_path)\n",
    "    for i in range(num_classes):\n",
    "        samples_per_class.append(batch_size//num_classes)\n",
    "    for i in range(batch_size%num_classes):\n",
    "        samples_per_class[i] += 1\n",
    "    instances_per_class = labels.sum(axis=0, numeric_only=True)\n",
    "    if verbose:\n",
    "        print(f\"loading images from {images_path} and labels from {labels_path} with equal sampling\")\n",
    "    for i in range(num_classes):\n",
    "        #get all row indexes with 1 in ith row\n",
    "        class_indexes = []\n",
    "        p = 0\n",
    "        for x in labels.iloc:\n",
    "            if x[i+1] == 1:\n",
    "                class_indexes.append(p)\n",
    "            p+=1\n",
    "        print(f\"samples for {i} class: {samples_per_class[i]}, class_indexes len: {len(class_indexes)}\")\n",
    "        for x in range(samples_per_class[i]):\n",
    "            random_index = np.random.randint(0, instances_per_class[i])\n",
    "            ind = class_indexes[random_index]\n",
    "            img = cv2.imread(os.path.join(images_path, images[ind]))\n",
    "            row = labels.iloc[ind, 1:]\n",
    "            if img is not None and row is not None:\n",
    "                if not (samples_per_class[i] >= len(class_indexes)-1):               \n",
    "                    class_indexes.pop(random_index)\n",
    "                    instances_per_class[i] -= 1\n",
    "                ds_images.append(np.array(cv2.resize(img, dsize=image_shape), dtype=\"uint8\"))\n",
    "                #assuming 1 column for image id\n",
    "                #ds_labels.append(row.values) #for array labels\n",
    "                ds_labels.append(class_names[np.where(row.values == 1)[0][0]]) #for string labels - make sure to remove .astype for labels\n",
    "                #ds_labels.append(np.where(row.values == 1)[0][0]) #for integer labels\n",
    "        print(\"1 class loaded\")\n",
    "        print(f\"len ds_images: {len(ds_images)}\")\n",
    "        print(f\"len ds_labels: {len(ds_labels)}\")\n",
    "    return np.array(ds_images).astype(np.uint8), pd.get_dummies(ds_labels).to_numpy()#k.utils.to_categorical(ds_labels, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "loading images from train/ISIC2018_Task3_Training_Input/ and labels from train_ground_truth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv with equal sampling\n",
      "samples for 0 class: 275, class_indexes len: 1113\n",
      "1 class loaded\n",
      "len ds_images: 275\n",
      "len ds_labels: 275\n",
      "samples for 1 class: 275, class_indexes len: 6705\n",
      "1 class loaded\n",
      "len ds_images: 550\n",
      "len ds_labels: 550\n",
      "samples for 2 class: 274, class_indexes len: 514\n",
      "1 class loaded\n",
      "len ds_images: 824\n",
      "len ds_labels: 824\n",
      "samples for 3 class: 274, class_indexes len: 327\n",
      "1 class loaded\n",
      "len ds_images: 1098\n",
      "len ds_labels: 1098\n",
      "samples for 4 class: 274, class_indexes len: 1099\n",
      "1 class loaded\n",
      "len ds_images: 1372\n",
      "len ds_labels: 1372\n",
      "samples for 5 class: 274, class_indexes len: 115\n",
      "1 class loaded\n",
      "len ds_images: 1646\n",
      "len ds_labels: 1646\n",
      "samples for 6 class: 274, class_indexes len: 142\n",
      "1 class loaded\n",
      "len ds_images: 1920\n",
      "len ds_labels: 1920\n",
      "loading images from validation/ISIC2018_Task3_Validation_Input/ and labels from validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv with equal sampling\n",
      "samples for 0 class: 138, class_indexes len: 21\n",
      "1 class loaded\n",
      "len ds_images: 138\n",
      "len ds_labels: 138\n",
      "samples for 1 class: 137, class_indexes len: 123\n",
      "1 class loaded\n",
      "len ds_images: 275\n",
      "len ds_labels: 275\n",
      "samples for 2 class: 137, class_indexes len: 15\n",
      "1 class loaded\n",
      "len ds_images: 396\n",
      "len ds_labels: 396\n",
      "samples for 3 class: 137, class_indexes len: 8\n",
      "1 class loaded\n",
      "len ds_images: 533\n",
      "len ds_labels: 533\n",
      "samples for 4 class: 137, class_indexes len: 22\n",
      "1 class loaded\n",
      "len ds_images: 670\n",
      "len ds_labels: 670\n",
      "samples for 5 class: 137, class_indexes len: 1\n",
      "1 class loaded\n",
      "len ds_images: 807\n",
      "len ds_labels: 807\n",
      "samples for 6 class: 137, class_indexes len: 3\n",
      "1 class loaded\n",
      "len ds_images: 944\n",
      "len ds_labels: 944\n",
      "[[False False False ...  True False False]\n",
      " [False False False ...  True False False]\n",
      " [False False False ...  True False False]\n",
      " ...\n",
      " [False False False ... False False  True]\n",
      " [False False False ... False False  True]\n",
      " [False False False ... False False  True]]\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 15:55:38.769413: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2024-02-03 15:55:51.564069: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inclassification/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-02-03 15:59:02.042662: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    }
   ],
   "source": [
    "#classification = k.models.load_model('classification.keras') #reset weights\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "classification.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f_score, precision_score, 'AUC']) \n",
    "\n",
    "callback_list = []#[tf.keras.callbacks.EarlyStopping(patience=1.5)] #can adjust to improve accuracy\n",
    "\"\"\"\n",
    "batch_size=32\n",
    "spe = 2 #steps per epoch\n",
    "epochs = 50 # set to 1 for debugging purposes\n",
    "\"\"\"\n",
    "\n",
    "seed = 123\n",
    "\n",
    "cls_val = r'validation/ISIC2018_Task3_Validation_Input/'\n",
    "cls_val_gt = \"validation_ground_truth/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
    "\n",
    "cls_train = r'train/ISIC2018_Task3_Training_Input/'#r\"classi/ISIC2018_Task3_Training_Input/ISIC2018_Task3_Training_Input/\" \n",
    "cls_train_gt = 'train_ground_truth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'#(\"classi/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\")\n",
    "cls_train_gt_ham10000 = 'ham10000/HAM10000_metadata.csv'\n",
    "\n",
    "epochs=60\n",
    "batch_size = 2\n",
    "spe=16\n",
    "\"\"\"\n",
    "length=len(pd.read_csv(cls_train_gt))//64\n",
    "b_max= 60 # set this based on  how much your  memory can hold\n",
    "batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and \n",
    "                  length/n<=b_max],reverse=True)[0] \n",
    "spe=int(length/batch_size)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(batch_size*spe*epochs)\n",
    "#df_train= pd.read_csv(cls_train_gt_ham10000)\n",
    "#df_validation = pd.read_csv\n",
    "train_ds, train_gt = load_images_and_labels_equal(cls_train, cls_train_gt, batch_size*spe*epochs, 7, (256,256), True)\n",
    "val_ds, val_gt = load_images_and_labels_equal(cls_val, cls_val_gt, batch_size*spe*epochs//2, 7, (256,256), True)\n",
    "print(train_gt)\n",
    "#train_data = cls_datagen.flow_from_dataframe(dataframe=df_train, directory=cls_train, x_col=\"image_id\", y_col=\"dx\", target_size=(256,256), batch_size=epochs*batch_size*spe, shuffle=True)\n",
    "#validation_data = cls_datagen.flow_from_dataframe(dataframe=df, directory=cls_train, x_col=\"image_id\", y_col=\"dx\", target_size=(256,256), batch_size=epochs*batch_size*spe, shuffle=True)\n",
    "#print(f\"train_ds len: {len(train_ds)}, train labels len: {len(train_gt)}\")\n",
    "#print(f\"val_ds len: {len(val_ds)}, val labels len: {len(val_gt)}\")\n",
    "cls_train_gen = cls_datagen.flow(x=train_ds, y=train_gt, seed=seed, batch_size=batch_size*spe, shuffle=False)\n",
    "val_train_gen = cls_datagen.flow(x=val_ds, y=val_gt, seed=seed, batch_size=batch_size*spe//2, shuffle=False)\n",
    "\n",
    "history = classification.fit(cls_train_gen, steps_per_epoch=len(cls_train_gen.x)//cls_train_gen.batch_size, epochs=epochs,\n",
    "                                #class_weight=get_weights(pd.read_csv(cls_train_gt)), \n",
    "                                batch_size=batch_size, callbacks=callback_list, verbose=1,\n",
    "                                validation_data=(val_train_gen.x, val_train_gen.y), validation_steps=len(val_train_gen.x)//val_train_gen.batch_size)\n",
    "\n",
    "print(f\"--------------- Done training -----------------\")\n",
    "\n",
    "classification.save_weights(\"classification_final.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 600, 3)\n",
      "(256, 256, 3)\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "True Label:            image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
      "71  ISIC_0034596  0.0  0.0  0.0    0.0  1.0  0.0   0.0\n",
      "Predicted Scores: [[0.06108923 0.02101576 0.49388093 0.01784678 0.05285696 0.23285656\n",
      "  0.12045382]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to BCC with a 49.39 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "#Individual Image Testing\n",
    "class_names=[\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "pred_folder = \"test/ISIC2018_Task3_Test_Input\"\n",
    "pred_image = \"ISIC_0034596\"\n",
    "labels_path = \"test_ground_truth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\"\n",
    "#classification = k.models.load_model(\"final_class.keras\", custom_objects={\"f_score\": f_score, \"precision_score\": precision_score}) # make sure to run only after training the classification model\n",
    "\n",
    "\n",
    "pred_label_df = pd.read_csv(labels_path)\n",
    "pred_label_true = pred_label_df.loc[pred_label_df['image']==pred_image]\n",
    "\n",
    "test_image = np.array(cv2.imread(os.path.join(pred_folder, pred_image) + \".jpg\"))\n",
    "print(test_image.shape)\n",
    "#plt.imshow(test_image, interpolation='nearest')\n",
    "#plt.show()\n",
    "\n",
    "pred_image = cv2.resize(test_image, (256,256))\n",
    "print(pred_image.shape)\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(pred_image)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "score = classification.predict(img_array)\n",
    "\"\"\"\n",
    "TF_MODEL_FILE_PATH = 'cls_final_withresampling3.tflite' # The default path to the saved TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)\n",
    "sig_dict = interpreter.get_signature_list()\n",
    "print(f\"sig_dict = {sig_dict}\")\n",
    "sig = list(sig_dict)[0]\n",
    "print(f'sig = {sig}')\n",
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "print(classify_lite)\n",
    "predictions_lite = classify_lite(input_2=img_array)['dense_2']\n",
    "score_lite = tf.nn.softmax(predictions_lite)\n",
    "\"\"\"\n",
    "label_name = class_names[np.argmax(score)]\n",
    "confidence_percent = 100 * np.max(score)\n",
    "\n",
    "\n",
    "print(f\"True Label: {pred_label_true}\")\n",
    "\n",
    "print(f\"Predicted Scores: {score}\")\n",
    "plt.imshow(score, interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(label_name, confidence_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Graph Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval\n",
    "train_loss = history.history['loss']\n",
    "val_loss   = history.history['val_loss']\n",
    "#train_acc  = history.history['acc']\n",
    "#val_acc    = history.history['val_acc']\n",
    "xc         = range(10)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(xc, train_loss)\n",
    "#plt.plot(xc, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_images_and_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x_test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/ISIC2018_Task3_Test_Input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m y_test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_ground_truth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m load_images_and_labels(x_test_path, y_test_path, \u001b[38;5;28mlen\u001b[39m(pd\u001b[38;5;241m.\u001b[39mread_csv(y_test_path)), (\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m classification\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      7\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax (y_prediction, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_images_and_labels' is not defined"
     ]
    }
   ],
   "source": [
    "x_test_path = \"test/ISIC2018_Task3_Test_Input\"\n",
    "y_test_path = \"test_ground_truth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\"\n",
    "\n",
    "x_test, y_test = load_images_and_labels(x_test_path, y_test_path, len(pd.read_csv(y_test_path)), (256,256), True)\n",
    "\n",
    "y_prediction = classification.predict(x_test)\n",
    "y_prediction = np.argmax (y_prediction, axis = 1)\n",
    "y_test=np.argmax(y_test, axis=1)\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(result, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(result.shape[1]):\n",
    "        ax.text(x=j, y=i,s=np.round(result[i, j], 3), va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, name):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(str(name), 'wb') as f:\n",
    "      f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convert_to_tflite(classification, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls_final.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mconvert_to_tflite\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tflite\u001b[39m(model, name):\n\u001b[1;32m      2\u001b[0m     converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[0;32m----> 3\u001b[0m     tflite_model \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Save the model.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(name), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:1139\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1138\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:1093\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1092\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1093\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1094\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:1601\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1601\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_as_saved_model()\n\u001b[1;32m   1602\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:1579\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1576\u001b[0m temp_dir \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mmkdtemp()\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1578\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1579\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir)\n\u001b[1;32m   1580\u001b[0m   )\n\u001b[1;32m   1581\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m   1583\u001b[0m         graph_def, input_tensors, output_tensors\n\u001b[1;32m   1584\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:1502\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_keras_to_saved_model\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save Keras model to the SavedModel format.\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \n\u001b[1;32m   1493\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;124;03m  output_tensors: List of output tensors.\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m   _save\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m   1503\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model,\n\u001b[1;32m   1504\u001b[0m       output_dir,\n\u001b[1;32m   1505\u001b[0m       options\u001b[38;5;241m=\u001b[39m_save_options\u001b[38;5;241m.\u001b[39mSaveOptions(save_debug_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m   \u001b[38;5;66;03m# When storing the given keras model to a saved model is failed, let's\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m   \u001b[38;5;66;03m# use original keras model conversion pipeline.\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1336\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1336\u001b[0m save_and_return_nodes(obj, export_dir, signatures, options)\n\u001b[1;32m   1338\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1371\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1368\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1370\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1371\u001b[0m     _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[1;32m   1372\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1373\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1584\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1495\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1493\u001b[0m augmented_graph_view \u001b[38;5;241m=\u001b[39m _AugmentedGraphView(obj)\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1495\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1496\u001b[0m       augmented_graph_view\n\u001b[1;32m   1497\u001b[0m   )\n\u001b[1;32m   1499\u001b[0m signatures, wrapped_functions, defaults \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1500\u001b[0m     signature_serialization\u001b[38;5;241m.\u001b[39mcanonicalize_signatures(signatures)\n\u001b[1;32m   1501\u001b[0m )\n\u001b[1;32m   1502\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/signature_serialization.py:109\u001b[0m, in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m possible_signatures \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, (def_function\u001b[38;5;241m.\u001b[39mFunction, defun\u001b[38;5;241m.\u001b[39mConcreteFunction)):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:189\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache:\n\u001b[1;32m    187\u001b[0m   children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache[obj] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 189\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(_AugmentedGraphView, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mlist_children(\n\u001b[1;32m    190\u001b[0m       obj,\n\u001b[1;32m    191\u001b[0m       save_type\u001b[38;5;241m=\u001b[39mbase\u001b[38;5;241m.\u001b[39mSaveType\u001b[38;5;241m.\u001b[39mSAVEDMODEL,\n\u001b[1;32m    192\u001b[0m       cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialization_cache):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m    194\u001b[0m       child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m children \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(ObjectGraphView,\n\u001b[1;32m     76\u001b[0m                        \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mchildren(obj, save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     77\u001b[0m   children\u001b[38;5;241m.\u001b[39mappend(base\u001b[38;5;241m.\u001b[39mTrackableReference(name, ref))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/checkpoint/trackable_view.py:84\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[0;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m obj\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n\u001b[1;32m     83\u001b[0m children \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     85\u001b[0m   ref \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert_to_trackable(ref, parent\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m     86\u001b[0m   children[name] \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/functional.py:460\u001b[0m, in \u001b[0;36mFunctional._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_trackable_children\u001b[39m(\u001b[38;5;28mself\u001b[39m, save_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    459\u001b[0m     dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_checkpoint_dependencies\n\u001b[0;32m--> 460\u001b[0m     dependencies\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dependencies\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:4031\u001b[0m, in \u001b[0;36mModel._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   4028\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_tf_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4031\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   4033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavedmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4034\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m train_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/base_layer.py:3470\u001b[0m, in \u001b[0;36mLayer._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     cache \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3467\u001b[0m     \u001b[38;5;66;03m# TODO(b/213628533): This must be called before super() to ensure\u001b[39;00m\n\u001b[1;32m   3468\u001b[0m     \u001b[38;5;66;03m# that any input shape changes are applied before getting the config\u001b[39;00m\n\u001b[1;32m   3469\u001b[0m     \u001b[38;5;66;03m# of the model.\u001b[39;00m\n\u001b[0;32m-> 3470\u001b[0m     children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trackable_saved_model_saver\u001b[38;5;241m.\u001b[39mtrackable_children(\n\u001b[1;32m   3471\u001b[0m         cache\n\u001b[1;32m   3472\u001b[0m     )\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3474\u001b[0m     children \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/base_serialization.py:61\u001b[0m, in \u001b[0;36mSavedModelSaver.trackable_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mshould_save_traces():\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m---> 61\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects_to_serialize(serialization_cache)\n\u001b[1;32m     62\u001b[0m children\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions_to_serialize(serialization_cache))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:79\u001b[0m, in \u001b[0;36mLayerSavedModelSaver.objects_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjects_to_serialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, serialization_cache):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_serialized_attributes(\n\u001b[1;32m     80\u001b[0m         serialization_cache\n\u001b[1;32m     81\u001b[0m     )\u001b[38;5;241m.\u001b[39mobjects_to_serialize\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    101\u001b[0m     save_impl\u001b[38;5;241m.\u001b[39mshould_skip_serialization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_must_restore_from_config\n\u001b[1;32m    103\u001b[0m ):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialized_attr\n\u001b[0;32m--> 106\u001b[0m object_dict, function_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_serialized_attributes_internal(\n\u001b[1;32m    107\u001b[0m     serialization_cache\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[1;32m    111\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/model_serialization.py:57\u001b[0m, in \u001b[0;36mModelSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_signature \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mdefault_save_signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Other than the default signature function, all other attributes match\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# with the ones serialized by Layer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m objects, functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_get_serialized_attributes_internal(\n\u001b[1;32m     58\u001b[0m     serialization_cache\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m default_signature\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objects, functions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m objects \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache)\n\u001b[0;32m--> 117\u001b[0m functions \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_functions(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:168\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    162\u001b[0m         fn_name: \u001b[38;5;28mgetattr\u001b[39m(layer\u001b[38;5;241m.\u001b[39mkeras_api, fn_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m fn_name \u001b[38;5;129;01min\u001b[39;00m serialized_attributes\u001b[38;5;241m.\u001b[39mLayerAttributes\u001b[38;5;241m.\u001b[39mall_functions\n\u001b[1;32m    164\u001b[0m     }\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Reset the losses of the layer and its children. The call function in each\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# child layer is replaced with tf.functions.\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m original_fns \u001b[38;5;241m=\u001b[39m _replace_child_layer_functions(layer, serialization_cache)\n\u001b[1;32m    169\u001b[0m original_losses \u001b[38;5;241m=\u001b[39m _reset_layer_losses(layer)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Wrap all the layer call and activity regularizer functions.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Use LayerCallCollection to ensure that all layer call functions (__call__,\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# call with losses) are traced with the same inputs.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:305\u001b[0m, in \u001b[0;36m_replace_child_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m child_layer \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m serialization_cache[constants\u001b[38;5;241m.\u001b[39mKERAS_CACHE_KEY]:\n\u001b[0;32m--> 305\u001b[0m     serialized_functions \u001b[38;5;241m=\u001b[39m child_layer\u001b[38;5;241m.\u001b[39m_trackable_saved_model_saver\u001b[38;5;241m.\u001b[39m_get_serialized_attributes(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    306\u001b[0m         serialization_cache\n\u001b[1;32m    307\u001b[0m     )\u001b[38;5;241m.\u001b[39mfunctions\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     serialized_functions \u001b[38;5;241m=\u001b[39m serialization_cache[\n\u001b[1;32m    310\u001b[0m         constants\u001b[38;5;241m.\u001b[39mKERAS_CACHE_KEY\n\u001b[1;32m    311\u001b[0m     ][child_layer]\u001b[38;5;241m.\u001b[39mfunctions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    101\u001b[0m     save_impl\u001b[38;5;241m.\u001b[39mshould_skip_serialization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_must_restore_from_config\n\u001b[1;32m    103\u001b[0m ):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialized_attr\n\u001b[0;32m--> 106\u001b[0m object_dict, function_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_serialized_attributes_internal(\n\u001b[1;32m    107\u001b[0m     serialization_cache\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[1;32m    111\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/model_serialization.py:57\u001b[0m, in \u001b[0;36mModelSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_signature \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mdefault_save_signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Other than the default signature function, all other attributes match\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# with the ones serialized by Layer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m objects, functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_get_serialized_attributes_internal(\n\u001b[1;32m     58\u001b[0m     serialization_cache\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m default_signature\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objects, functions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m objects \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache)\n\u001b[0;32m--> 117\u001b[0m functions \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_functions(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:168\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    162\u001b[0m         fn_name: \u001b[38;5;28mgetattr\u001b[39m(layer\u001b[38;5;241m.\u001b[39mkeras_api, fn_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m fn_name \u001b[38;5;129;01min\u001b[39;00m serialized_attributes\u001b[38;5;241m.\u001b[39mLayerAttributes\u001b[38;5;241m.\u001b[39mall_functions\n\u001b[1;32m    164\u001b[0m     }\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Reset the losses of the layer and its children. The call function in each\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# child layer is replaced with tf.functions.\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m original_fns \u001b[38;5;241m=\u001b[39m _replace_child_layer_functions(layer, serialization_cache)\n\u001b[1;32m    169\u001b[0m original_losses \u001b[38;5;241m=\u001b[39m _reset_layer_losses(layer)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Wrap all the layer call and activity regularizer functions.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Use LayerCallCollection to ensure that all layer call functions (__call__,\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# call with losses) are traced with the same inputs.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:305\u001b[0m, in \u001b[0;36m_replace_child_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m child_layer \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m serialization_cache[constants\u001b[38;5;241m.\u001b[39mKERAS_CACHE_KEY]:\n\u001b[0;32m--> 305\u001b[0m     serialized_functions \u001b[38;5;241m=\u001b[39m child_layer\u001b[38;5;241m.\u001b[39m_trackable_saved_model_saver\u001b[38;5;241m.\u001b[39m_get_serialized_attributes(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    306\u001b[0m         serialization_cache\n\u001b[1;32m    307\u001b[0m     )\u001b[38;5;241m.\u001b[39mfunctions\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     serialized_functions \u001b[38;5;241m=\u001b[39m serialization_cache[\n\u001b[1;32m    310\u001b[0m         constants\u001b[38;5;241m.\u001b[39mKERAS_CACHE_KEY\n\u001b[1;32m    311\u001b[0m     ][child_layer]\u001b[38;5;241m.\u001b[39mfunctions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    101\u001b[0m     save_impl\u001b[38;5;241m.\u001b[39mshould_skip_serialization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_must_restore_from_config\n\u001b[1;32m    103\u001b[0m ):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialized_attr\n\u001b[0;32m--> 106\u001b[0m object_dict, function_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_serialized_attributes_internal(\n\u001b[1;32m    107\u001b[0m     serialization_cache\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[1;32m    111\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m objects \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache)\n\u001b[0;32m--> 117\u001b[0m functions \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_functions(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:216\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    211\u001b[0m     fns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_and_return_all_conditional_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m call_fn_with_losses\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Manually trigger traces before restoring the overwritten functions. The\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# functions are traced within the layer call context to ensure that layer\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# functions (e.g. add_loss) behave as though running in graph mode.\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing_scope():\n\u001b[1;32m    217\u001b[0m     call_collection\u001b[38;5;241m.\u001b[39mtrace_with_input_signature()\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m    219\u001b[0m         layer, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:390\u001b[0m, in \u001b[0;36mtracing_scope\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mdeprecated_internal_learning_phase_scope(training):\n\u001b[0;32m--> 390\u001b[0m         fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1213\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m   1204\u001b[0m       args,\n\u001b[1;32m   1205\u001b[0m       kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1208\u001b[0m       ),\n\u001b[1;32m   1209\u001b[0m   )\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m   \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m   \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m-> 1213\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m   1214\u001b[0m       args,\n\u001b[1;32m   1215\u001b[0m       kwargs,\n\u001b[1;32m   1216\u001b[0m       dataclasses\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m   1217\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config, bind_graph_to_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m       ),\n\u001b[1;32m   1219\u001b[0m   )\n\u001b[1;32m   1220\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1222\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:632\u001b[0m, in \u001b[0;36mlayer_call_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m    623\u001b[0m     layer,\n\u001b[1;32m    624\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    628\u001b[0m ):\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    630\u001b[0m         layer\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    631\u001b[0m     ):\n\u001b[0;32m--> 632\u001b[0m         ret \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    633\u001b[0m _restore_layer_losses(original_losses)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/utils.py:190\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[38;5;241m=\u001b[39m call_spec\u001b[38;5;241m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_call(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m control_flow_util\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m    191\u001b[0m     training,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: replace_training_and_call(\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: replace_training_and_call(\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m    109\u001b[0m     pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/smart_cond.py:55\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m cond\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn,\n\u001b[1;32m     58\u001b[0m                    name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/utils.py:193\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[38;5;241m=\u001b[39m call_spec\u001b[38;5;241m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_call(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m control_flow_util\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m    191\u001b[0m     training,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: replace_training_and_call(\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: replace_training_and_call(\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/utils.py:188\u001b[0m, in \u001b[0;36mmaybe_add_training_arg.<locals>.wrap_with_training_arg.<locals>.replace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace_training_and_call\u001b[39m(training):\n\u001b[1;32m    185\u001b[0m     new_args, new_kwargs \u001b[38;5;241m=\u001b[39m call_spec\u001b[38;5;241m.\u001b[39mset_arg_value(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, training, args, kwargs, inputs_in_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_call(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/save_impl.py:698\u001b[0m, in \u001b[0;36m_wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_and_return_conditional_losses\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m     call_output \u001b[38;5;241m=\u001b[39m layer_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version_utils\u001b[38;5;241m.\u001b[39mis_v1_layer_or_model(layer):\n\u001b[1;32m    700\u001b[0m         conditional_losses \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mget_losses_for(\n\u001b[1;32m    701\u001b[0m             _filtered_inputs([args, kwargs])\n\u001b[1;32m    702\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:597\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused:\n\u001b[0;32m--> 597\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fused_batch_norm(\n\u001b[1;32m    598\u001b[0m         inputs, mask\u001b[38;5;241m=\u001b[39mmask, training\u001b[38;5;241m=\u001b[39mtraining\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;66;03m# Currently never reaches here since fused_batch_norm does not\u001b[39;00m\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;66;03m# support virtual batching\u001b[39;00m\n\u001b[1;32m    603\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:990\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fused_batch_norm_inference\u001b[39m():\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfused_batch_norm(\n\u001b[1;32m    980\u001b[0m         inputs,\n\u001b[1;32m    981\u001b[0m         gamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format,\n\u001b[1;32m    988\u001b[0m     )\n\u001b[0;32m--> 990\u001b[0m output, mean, variance \u001b[38;5;241m=\u001b[39m control_flow_util\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m    991\u001b[0m     training, _fused_batch_norm_training, _fused_batch_norm_inference\n\u001b[1;32m    992\u001b[0m )\n\u001b[1;32m    993\u001b[0m variance \u001b[38;5;241m=\u001b[39m _maybe_add_or_remove_bessels_correction(\n\u001b[1;32m    994\u001b[0m     variance, remove\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    995\u001b[0m )\n\u001b[1;32m    997\u001b[0m training_value \u001b[38;5;241m=\u001b[39m control_flow_util\u001b[38;5;241m.\u001b[39mconstant_value(training)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[1;32m    109\u001b[0m     pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/smart_cond.py:55\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m cond\u001b[38;5;241m.\u001b[39mcond(pred, true_fn\u001b[38;5;241m=\u001b[39mtrue_fn, false_fn\u001b[38;5;241m=\u001b[39mfalse_fn,\n\u001b[1;32m     58\u001b[0m                    name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:979\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>._fused_batch_norm_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fused_batch_norm_inference\u001b[39m():\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfused_batch_norm(\n\u001b[1;32m    980\u001b[0m         inputs,\n\u001b[1;32m    981\u001b[0m         gamma,\n\u001b[1;32m    982\u001b[0m         beta,\n\u001b[1;32m    983\u001b[0m         mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_mean,\n\u001b[1;32m    984\u001b[0m         variance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_variance,\n\u001b[1;32m    985\u001b[0m         epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[1;32m    986\u001b[0m         is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    987\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format,\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/nn_impl.py:1580\u001b[0m, in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1578\u001b[0m   variance \u001b[38;5;241m=\u001b[39m constant_op\u001b[38;5;241m.\u001b[39mconstant([])\n\u001b[0;32m-> 1580\u001b[0m y, running_mean, running_var, _, _, _ \u001b[38;5;241m=\u001b[39m gen_nn_ops\u001b[38;5;241m.\u001b[39mfused_batch_norm_v3(\n\u001b[1;32m   1581\u001b[0m     x,\n\u001b[1;32m   1582\u001b[0m     scale,\n\u001b[1;32m   1583\u001b[0m     offset,\n\u001b[1;32m   1584\u001b[0m     mean,\n\u001b[1;32m   1585\u001b[0m     variance,\n\u001b[1;32m   1586\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[1;32m   1587\u001b[0m     exponential_avg_factor\u001b[38;5;241m=\u001b[39mexponential_avg_factor,\n\u001b[1;32m   1588\u001b[0m     data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[1;32m   1589\u001b[0m     is_training\u001b[38;5;241m=\u001b[39mis_training,\n\u001b[1;32m   1590\u001b[0m     name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y, running_mean, running_var\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_nn_ops.py:5206\u001b[0m, in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   5204\u001b[0m   is_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   5205\u001b[0m is_training \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(is_training, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5206\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m _op_def_library\u001b[38;5;241m.\u001b[39m_apply_op_helper(\n\u001b[1;32m   5207\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFusedBatchNormV3\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, scale\u001b[38;5;241m=\u001b[39mscale, offset\u001b[38;5;241m=\u001b[39moffset, mean\u001b[38;5;241m=\u001b[39mmean,\n\u001b[1;32m   5208\u001b[0m                           variance\u001b[38;5;241m=\u001b[39mvariance, epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[1;32m   5209\u001b[0m                           exponential_avg_factor\u001b[38;5;241m=\u001b[39mexponential_avg_factor,\n\u001b[1;32m   5210\u001b[0m                           data_format\u001b[38;5;241m=\u001b[39mdata_format, is_training\u001b[38;5;241m=\u001b[39mis_training,\n\u001b[1;32m   5211\u001b[0m                           name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   5212\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   5213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 778\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    779\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    780\u001b[0m                            input_types)\n\u001b[1;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:551\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    545\u001b[0m       values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    546\u001b[0m           values,\n\u001b[1;32m    547\u001b[0m           name\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    548\u001b[0m           as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref,\n\u001b[1;32m    549\u001b[0m           preferred_dtype\u001b[38;5;241m=\u001b[39mdefault_dtype)\n\u001b[1;32m    550\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    552\u001b[0m         values,\n\u001b[1;32m    553\u001b[0m         name\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    554\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    555\u001b[0m         as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref,\n\u001b[1;32m    556\u001b[0m         preferred_dtype\u001b[38;5;241m=\u001b[39mdefault_dtype)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m    697\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m conversion_func(value, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname, as_ref\u001b[38;5;241m=\u001b[39mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:2340\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2340\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m var\u001b[38;5;241m.\u001b[39m_dense_var_to_tensor(dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname, as_ref\u001b[38;5;241m=\u001b[39mas_ref)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:1582\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1580\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:634\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_value\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 634\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:548\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_type(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 548\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m _op_def_library\u001b[38;5;241m.\u001b[39m_apply_op_helper(\n\u001b[1;32m    549\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, resource\u001b[38;5;241m=\u001b[39mresource, dtype\u001b[38;5;241m=\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    550\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:778\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m g\u001b[38;5;241m.\u001b[39mas_default(), ops\u001b[38;5;241m.\u001b[39mname_scope(name) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fallback:\n\u001b[0;32m--> 778\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    779\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    780\u001b[0m                            input_types)\n\u001b[1;32m    781\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    782\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    783\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:551\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    545\u001b[0m       values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    546\u001b[0m           values,\n\u001b[1;32m    547\u001b[0m           name\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    548\u001b[0m           as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref,\n\u001b[1;32m    549\u001b[0m           preferred_dtype\u001b[38;5;241m=\u001b[39mdefault_dtype)\n\u001b[1;32m    550\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    552\u001b[0m         values,\n\u001b[1;32m    553\u001b[0m         name\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    554\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    555\u001b[0m         as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref,\n\u001b[1;32m    556\u001b[0m         preferred_dtype\u001b[38;5;241m=\u001b[39mdefault_dtype)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m    697\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m overload(dtype, name)  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:590\u001b[0m, in \u001b[0;36m_EagerTensorBase.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    584\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mbuilding_function:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m         _add_error_prefix(\n\u001b[1;32m    587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to capture an EagerTensor without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilding a function.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    589\u001b[0m             name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m--> 590\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mcapture(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__tf_tensor__(dtype, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:675\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapture\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 675\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_captures\u001b[38;5;241m.\u001b[39mcapture_by_value(\u001b[38;5;28mself\u001b[39m, tensor, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/capture/capture_container.py:141\u001b[0m, in \u001b[0;36mFunctionCaptures.capture_by_value\u001b[0;34m(self, graph, tensor, name)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph_const\n\u001b[1;32m    140\u001b[0m   \u001b[38;5;66;03m# Large EagerTensors and resources are captured with Placeholder ops\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_placeholder_helper(graph, tensor, name)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m graph:\n\u001b[1;32m    144\u001b[0m   graph\u001b[38;5;241m.\u001b[39m_validate_in_scope(tensor)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/capture/capture_container.py:290\u001b[0m, in \u001b[0;36mFunctionCaptures._create_placeholder_helper\u001b[0;34m(self, graph, tensor, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_or_replace(\n\u001b[1;32m    287\u001b[0m       key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m(tensor), external\u001b[38;5;241m=\u001b[39mtensor, internal\u001b[38;5;241m=\u001b[39mplaceholder, is_by_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    288\u001b[0m   )\n\u001b[1;32m    289\u001b[0m   graph\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mappend(placeholder)\n\u001b[0;32m--> 290\u001b[0m placeholder\u001b[38;5;241m.\u001b[39m_record_tape(tensor)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m placeholder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:352\u001b[0m, in \u001b[0;36mTensor._record_tape\u001b[0;34m(self, capture)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(shape)\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_record_tape\u001b[39m(\u001b[38;5;28mself\u001b[39m, capture):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Connect this graph tensor with capture for gradients calculation.\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    355\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaptured_value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m       [\u001b[38;5;28mself\u001b[39m], [capture],\n\u001b[1;32m    357\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    358\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_to_tflite(classification, \"cls_final.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classification\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification_final.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m   3050\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\u001b[39;00m\n\u001b[1;32m   3052\u001b[0m \n\u001b[1;32m   3053\u001b[0m \u001b[38;5;124;03m    See the [Serialization and Saving guide](\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3101\u001b[0m \u001b[38;5;124;03m    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\u001b[39;00m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3103\u001b[0m     saving_api\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3105\u001b[0m         filepath\u001b[38;5;241m=\u001b[39mfilepath,\n\u001b[1;32m   3106\u001b[0m         overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m   3107\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[1;32m   3108\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3109\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:164\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         )\n\u001b[0;32m--> 164\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[1;32m    168\u001b[0m         model,\n\u001b[1;32m    169\u001b[0m         filepath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    173\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:159\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, weights_format)\u001b[0m\n\u001b[1;32m    156\u001b[0m _SAVING_V3_ENABLED\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 159\u001b[0m     serialized_model_dict \u001b[38;5;241m=\u001b[39m serialize_keras_object(model)\n\u001b[1;32m    160\u001b[0m config_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(serialized_model_dict)\n\u001b[1;32m    161\u001b[0m metadata_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m    162\u001b[0m     {\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: keras\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_saved\u001b[39m\u001b[38;5;124m\"\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    165\u001b[0m     }\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:260\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    255\u001b[0m     mod \u001b[38;5;129;01min\u001b[39;00m config_with_public_class[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m NON_SERIALIZABLE_CLASS_MODULES\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 260\u001b[0m get_build_and_compile_config(obj, config_with_public_class)\n\u001b[1;32m    261\u001b[0m record_object_after_serialization(obj, config_with_public_class)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config_with_public_class\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:298\u001b[0m, in \u001b[0;36mget_build_and_compile_config\u001b[0;34m(obj, config)\u001b[0m\n\u001b[1;32m    296\u001b[0m         config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m serialize_dict(build_config)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_compile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 298\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_compile_config()\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m serialize_dict(compile_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3658\u001b[0m, in \u001b[0;36mModel.get_compile_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a serialized config with information for compiling the model.\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \n\u001b[1;32m   3651\u001b[0m \u001b[38;5;124;03mThis method returns a config dictionary containing all the information\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;124;03m    A dict containing information for compiling the model.\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_compile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_config\u001b[38;5;241m.\u001b[39mserialize()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:59\u001b[0m, in \u001b[0;36mConfig.serialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialize_keras_object(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:162\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(config_arr) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m config_arr\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialize_dict(obj)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Special cases:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mbytes\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:403\u001b[0m, in \u001b[0;36mserialize_dict\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize_dict\u001b[39m(obj):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: serialize_keras_object(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:403\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize_dict\u001b[39m(obj):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: serialize_keras_object(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:240\u001b[0m, in \u001b[0;36mserialize_keras_object\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    229\u001b[0m         registered_name \u001b[38;5;241m=\u001b[39m object_registration\u001b[38;5;241m.\u001b[39mget_registered_name(\n\u001b[1;32m    230\u001b[0m             obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__typespec__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: spec_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistered_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: registered_name,\n\u001b[1;32m    238\u001b[0m     }\n\u001b[0;32m--> 240\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m _get_class_or_fn_config(obj)\n\u001b[1;32m    241\u001b[0m config_with_public_class \u001b[38;5;241m=\u001b[39m serialize_with_public_class(\n\u001b[1;32m    242\u001b[0m     obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, inner_config\n\u001b[1;32m    243\u001b[0m )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Add TF ops dispatch handler serialization for\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# ops.EagerTensor that contains nested numpy array.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Target: NetworkConstructionTest.test_constant_initializer_with_numpy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:385\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# All classes:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     config \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_config()\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `get_config()` method of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma dict. It returned: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/sgd.py:195\u001b[0m, in \u001b[0;36mSGD.get_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    191\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_config()\n\u001b[1;32m    193\u001b[0m     config\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    194\u001b[0m         {\n\u001b[0;32m--> 195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialize_hyperparameter(\n\u001b[1;32m    196\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate\n\u001b[1;32m    197\u001b[0m             ),\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum,\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnesterov\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesterov,\n\u001b[1;32m    200\u001b[0m         }\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/optimizer.py:726\u001b[0m, in \u001b[0;36m_BaseOptimizer._serialize_hyperparameter\u001b[0;34m(self, hyperparameter)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learning_rate_schedule\u001b[38;5;241m.\u001b[39mserialize(hyperparameter)\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hyperparameter, tf\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[0;32m--> 726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hyperparameter\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hyperparameter):\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hyperparameter()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:534\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m    535\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype)\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    537\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "classification.save(\"classification_final.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
